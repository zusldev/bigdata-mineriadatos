# Sabor Mexicano - Proyecto Integral de Data Mining y Big Data Style

Proyecto reproducible para analizar una cadena de 10 sucursales en MÃ©xico, respondiendo preguntas de negocio de ventas, rentabilidad, inventario, pronÃ³stico de demanda y segmentaciÃ³n de clientes.

## 1) Objetivo del proyecto

Este repositorio implementa:
- Ingesta flexible de `JSON`, `CSV` y `XLSX` con mapeo de esquema configurable.
- Pipeline modular por fases ejecutable como mÃ³dulo de Python.
- EDA + anÃ¡lisis de rentabilidad/inventario/digital.
- PronÃ³stico mensual por sucursal e ingrediente.
- SegmentaciÃ³n de clientes (RFM proxy + clustering).
- Recomendaciones accionables.
- Dashboard web con Streamlit para presentaciÃ³n.
- DocumentaciÃ³n tÃ©cnica en espaÃ±ol.

## 2) Estructura principal

```text
.
â”œâ”€â”€ apps/dashboard/app.py
â”œâ”€â”€ config/settings.yml
â”œâ”€â”€ config/schema_map.yml
â”œâ”€â”€ config/recipe_map.yml
â”œâ”€â”€ src/pipeline/run_all.py
â”œâ”€â”€ src/data/
â”œâ”€â”€ src/features/
â”œâ”€â”€ src/analysis/
â”œâ”€â”€ src/models/
â”œâ”€â”€ src/reco/
â”œâ”€â”€ src/report/
â”œâ”€â”€ data/raw/
â”œâ”€â”€ data/processed/
â”œâ”€â”€ outputs/
â”œâ”€â”€ reports/
â””â”€â”€ docs/
```

## 3) Requisitos

- Python `3.11` recomendado.
- Datos en:
  - `data/raw/json/*.json`
  - `data/raw/csv/*.csv` (opcional)
  - `data/raw/xlsx/*.xlsx`

InstalaciÃ³n:

```bash
python -m pip install --upgrade pip
python -m pip install -r requirements.txt
```

TambiÃ©n puedes usar:

```bash
make setup
```

## 4) EjecuciÃ³n del pipeline end-to-end

Comando principal (obligatorio):

```bash
python -m src.pipeline.run_all --seed 42 --forecast-horizon 6 --top-ingredients 12 --run-id <RUN_ID>
```

Este comando ejecuta las 4 fases:
1. Ingesta + limpieza + validaciÃ³n + EDA base + perfilado.
2. AnÃ¡lisis de rentabilidad, inventario y digital.
3. PronÃ³stico + segmentaciÃ³n.
4. Recomendaciones + generaciÃ³n de reportes y documentaciÃ³n.

### Requisito no negociable: rutina de estudio
Antes de correr pipeline debes actualizar:
- `docs/STUDY_LOG.md`
- `docs/GLOSSARY.md`
- `docs/DECISIONS.md`
- `docs/CHECKPOINTS.md`

El pipeline valida esto en modo fail-fast:
- `STUDY_LOG.md` debe contener `Run ID: <run_id>` o `NO_CHANGES: <run_id>`.
- Si no existe, la ejecuciÃ³n termina con error para forzar trazabilidad de aprendizaje.
- Ejemplo de run id: `2026-02-11-a`.

Corrida rÃ¡pida de verificaciÃ³n (sin cambios de cÃ³digo), ya preparada en Study Log:

```bash
python -m src.pipeline.run_all --seed 42 --forecast-horizon 6 --top-ingredients 12 --run-id 2026-02-11-quickcheck-01
```

## 5) Ejecutar dashboard

```bash
streamlit run apps/dashboard/app.py
```

Incluye pestaÃ±a dedicada: `ğŸ“š Aprender / Study Mode` con:
- resumen de conceptos por mÃ³dulo,
- render de docs de estudio,
- secciÃ³n â€œWhat changed in this run?â€ (diff-style),
- autoquiz (flashcards Q&A).

## 6) Comandos Makefile

```bash
make lint
make test
make pipeline
make dashboard
make all
```

Si estÃ¡s en Windows PowerShell y no tienes GNU Make, se instalÃ³ un shim `make` compatible con estos targets.
Puedes forzar intÃ©rprete Python con variable de entorno:

```powershell
$env:PYTHON = "python"
make pipeline
```

Nota:
- El `Makefile` prioriza automÃ¡ticamente `./.venv` si existe.
- `pytest` usa `outputs/.pytest_tmp` como temporal para evitar errores de permisos en `%TEMP%`.

## 7) Reproducibilidad y fallback parquet/csv

- Seed global controlado (`--seed`, default `42`).
- Persistencia preferente en Parquet.
- Si `pyarrow` no estÃ¡ disponible, el sistema cae automÃ¡ticamente a CSV y lo registra en logs/manifest.
- Manifest de artefactos: `outputs/manifests/artifacts_manifest.csv`.

## 8) Modo opcional POLARS=1

Para lecturas/agregaciones mÃ¡s rÃ¡pidas (si tienes `polars` instalado):

```bash
POLARS=1 python -m src.pipeline.run_all --seed 42 --forecast-horizon 6 --top-ingredients 12
```

Por defecto se usa `pandas` para simplicidad.

## 9) Archivos de salida relevantes

- `outputs/charts/*.html`: visualizaciones EDA.
- `outputs/tables/*.csv`: tablas analÃ­ticas, pronÃ³stico, segmentaciÃ³n y recomendaciones.
- `outputs/models/*.pkl`: artefactos de modelos.
- `outputs/logs/run_summary.md`: resumen automÃ¡tico de la corrida.
- `reports/final_report.md`: reporte final integral.
- `reports/RESULTS_SUMMARY.md`: resumen ejecutivo para directores.
- `docs/*.md`: metodologÃ­a, supuestos, diccionario de datos, perfil y rutina de estudio.

## 10) Docker (opcional)

Construir imagen:

```bash
docker build -t sabor-mexicano .
```

Ejecutar pipeline:

```bash
docker run --rm sabor-mexicano
```

Ejecutar dashboard:

```bash
docker run --rm -p 8501:8501 sabor-mexicano streamlit run apps/dashboard/app.py --server.address=0.0.0.0
```

## 11) Notas metodolÃ³gicas importantes

- El proyecto adopta prÃ¡cticas â€œBig Data styleâ€ sin sobreafirmar infraestructura distribuida:
  - pipeline modular y escalable,
  - schema mapping desacoplado,
  - outputs columnares parquet,
  - agregaciones partition-friendly.
- La segmentaciÃ³n RFM se construye en modo proxy con `clientes` (no hay llave transaccional cliente-venta).
